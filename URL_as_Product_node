using Revise
using Mill, HTTP, JLD2, Random, OneHotArrays, Flux, Statistics, IterTools, DataFrames, CSV, MLBase, SparseArrays


function main(ranges::Vector{<:AbstractRange}, percentage_of_data::Float64=0.1, prime::Int64=2053, ngrams::Int64=3, base::Int64=256)::Nothing

    # Read lines
    #all_urls = JLD2.load("Julia/Lines/new_combined_lines.jld2", "lines")     #  Load URL addresses
    #all_labels = JLD2.load("Julia/Lines/shuffled_labels.jld2", "labels_vector")      # Load labels for URLs
    
    all_urls = JLD2.load("new_mixed_urls.jld2", "vec_urls")     #  Load URL addresses
    all_labels = JLD2.load("new_mixed_labels.jld2", "vec_lab")      # Load labels for URLs
    # println(all_urls[1:100])
    # println(all_labels[1:100])

    # Generate random number every time
    random_seed = rand(UInt32)
    println("Seed: ", random_seed)
    new_indexing = randcycle(MersenneTwister(random_seed), length(all_urls))     # Generate permutation of set length, seed the generator with random_seed
    amount_of_training_data = Int(round(percentage_of_data*length(new_indexing)))     # Specify the amount of data wanted

    # Create the training data and the evaluation data 
    training_lines = all_urls[new_indexing[1:amount_of_training_data]]      # Choose training lines
    training_labels = all_labels[new_indexing[1:amount_of_training_data]]     # Choose training labels

    eval_lines = all_urls[new_indexing[amount_of_training_data:2*amount_of_training_data]]      # Choose eval lines
    eval_labels = all_labels[new_indexing[amount_of_training_data:2*amount_of_training_data]]     # Choose eval labels

    # Calculate the percentage of positive instances within the data
    per_of_positive_instances = round((sum(training_labels))/length(training_labels), digits = 2)
    println("Percentage of positive urls within the training lines: ", per_of_positive_instances)
    println("Percentage of positive urls within the eval lines: ", sum(eval_labels)/length(eval_labels))
    println("Number of instances within evaluation data: ", length(eval_labels))
    println("Number of positive urls within eval data: ", sum(eval_labels))

    # Prepare training and evaluation data
    training_urls = url_to_mill.(training_lines, ngrams, prime, base)
    eval_urls = url_to_mill.(eval_lines, ngrams, prime, base)
    # Construct additional parameters
    additional_params = Additional_params(Int64(random_seed), prime, round(100/percentage_of_data))

    # Construct parameter combinations to search
    par_comb = par_grid(ranges)     # Create a grid with possible values for each hyperparameter
    training_params = Training_params.(par_comb)    # Convert ranges into structs
    
    # Grid search for hyperparameters
    grid_search(training_urls, eval_urls, training_labels, eval_labels, training_params, additional_params)

    # Train model and get results on eval data
    #predicted_labels, params_of_model = train(training_urls, eval_urls, training_labels, eval_labels, network_param)

    # Save results to a file
    #eval_mod.eval_model("Julia/Model_eval.txt", eval_labels .+ 1, predicted_labels, network_param)

    return nothing
end

# Struct that holds training parameters for grid search
mutable struct Training_params{T<:Int64, S<:Float64}
    epochs::T
    batchsize::T
    path_neur_1::T
    path_neur_2::T
    query_neur_1::T
    query_neur_2::T
    path_query_neur::T
    learning_rate::S
end
# Outer constructor
function Training_params(vec::Vector{Float64})
    if length(vec) != 8
        error("Input vector must have exactly 8 elements")
    end
    ints = Int64.(vec[1:end-1])
    floats = vec[end]
    Training_params(ints..., floats) #splat the vector
end

struct Additional_params{T<:Int64, S<:Float64}
    seed::T
    prime::T
    percentage_of_data::S
end

# Takes in a URL as string and divides it, then creates bagnodes and finally a single product node for single URL
function url_to_mill(input::String, ngrams::Int64, prime::Int64, base::Int64)::ProductNode

    url = HTTP.URI(input) # Create "URL" type
    
    # Create parts of the URL
    host = url.host
    path = url.path
    query = url.query

    path = path[2:end] # Remove the first 

    # Prepare input into functions
    host = String.(split(host,"."))
    path = filter(!isempty, String.(split(path,"/")))
    query = String.(split(query,"&"))

    # Will not be including host into the product node, since it is the same for all url withing the training set
    # model = Mill.ProductNode((transform(path, ngrams, prime, base), 
    #                          transform(query, ngrams, prime, base)
    #                             ))

    model = Mill.ProductNode((transform(host,ngrams, prime, base),
                             transform(path, ngrams, prime, base), 
                             transform(query, ngrams, prime, base)
                                ))
    return model
end

# Transforms vector string[URL] into a BagNode
function transform(input::Vector{String}, ngrams::Int64, prime::Int64, base::Int64, sparse = false)::BagNode
    # Check for empty path
    if isempty(input)
        input = [""]
    end
    matrix = Mill.NGramMatrix(input, ngrams, base, prime)    # Create NGramMatrix from the string
    matrix = sparse ? SparseMatrixCSC(matrix) : matrix
    bn = Mill.BagNode(Mill.ArrayNode(matrix), [1:length(input)])     # NgramMatrix can act as ArrayNode data
    return bn
end

# Check if the present activation functions can be evaluated from the string - if they even exist# Epochs, batchsize, path_neur1, path_neur_2, query_neur_1, query_neur_2, percentage, learning rate = 0.001,prime = 2053, ngrams = 3, base = 256
function check_activation_func(str::String)::Nothing
    funcs = ["relu", "sigmoid", "tanh", "elu"]
    in(str, funcs) ? true : error("Incorrect activation function!")
    return nothing
end

# Struct for holding evaluation results of a model
struct Evaluation
    recall::Float64
    precision::Float64
    true_pos::Int64
    false_pos::Int64
    true_neg::Int64
    false_neg::Int64
    F_score::Float64
end

# Evaluate the performance of trained model
function evaluate_performance(true_labels::Vector{Int64}, predicted_labels::Vector{Int64})::Evaluation

    # Create consufion matrix
    conf_matrix = confusmat(2, true_labels.+1, predicted_labels)

    # Calculate precison 
    precis = (conf_matrix[2,2])/(conf_matrix[2,2] + conf_matrix[1,2])

    # Calculate recall
    recal = (conf_matrix[2,2])/(conf_matrix[2,2] + conf_matrix[2,1])

    # F_score
    f_score = round(2 * (precis * recal)/(precis+recal), digits = 2)

    return Evaluation(round(recal, digits = 2), round(precis, digits = 2), conf_matrix[1,1], conf_matrix[2,1], conf_matrix[2,2], conf_matrix[1,2], f_score)
end

# Create the model with specific parameters
function create_model(param::Training_params, prime::Int64)::ProductModel
    mod = Mill.ProductModel(tuple(
        Mill.BagModel(Mill.ArrayModel(Flux.Dense(prime => param.path_neur_1, bias = true, elu)), 
                      Mill.SegmentedMeanMax(param.path_neur_1), Flux.Dense(2*param.path_neur_1 => param.path_neur_2, bias = true, relu)),
        Mill.BagModel(Mill.ArrayModel(Flux.Dense(prime => param.query_neur_1, bias = true, elu)), 
                      Mill.SegmentedMeanMax(param.query_neur_1), Flux.Dense(2*param.query_neur_1=> param.query_neur_2, bias = true, relu))
                            ), Flux.Chain(Flux.Dense(param.path_neur_2 + param.query_neur_2 => param.path_query_neur, bias = true, elu), Flux.Dense(param.path_query_neur=>2))
                            )
    return mod
end

# Training function
function train(training_urls::Vector{<:ProductNode}, eval_urls::Vector{<:ProductNode}, training_labels::Vector{Int64}, eval_labels::Vector{Int64}, param::Training_params{Int64}, prime::Int64)::Tuple 
    
    # Create model of the network
    model = create_model(param, prime) # What with the activation functions

    # Create a loss
    loss(ds, y) = Flux.Losses.logitbinarycrossentropy(model(ds), OneHotArrays.onehotbatch(y .+ 1, 1:2))  # Onehot inside from training labels

    # Accuracy function
    acc(ds, y) = Statistics.mean(Flux.onecold(model(ds)) .== y.+ 1)    # Reverse of Onehot back to pure labels from the output matrix and calculating the mean of correctly predicted labels

    # Optimizer
    opt = Flux.Optimiser(ClipValue(1e-3), Adam(1e-3))
    par = Flux.params(model)    # Parameters of the model

    # Create minibatches
    training_data_loader = Flux.DataLoader((training_urls, training_labels), batchsize = param.batchsize, shuffle = true, partial = false)
    eval_data_loader = Flux.DataLoader((eval_urls, eval_labels), batchsize = param.batchsize, shuffle = true, partial = false)

    # Early stopping
    # Stopping  criteria for training loop
    state = Dict("best_loss" => Inf, "no_improv" => 0, "patience"=> 10)

    # Early stopping callback
    function early_stop_cb()::Bool
        eval_loss = mean(loss(batch...) for batch in eval_data_loader)
        println(acc(eval_urls, eval_labels))
        if eval_loss < state["best_loss"]
            state["best_loss"] = eval_loss
            state["no_improv"] = 0
        else
            state["no_improv"] += 1
        end
        return state["no_improv"] > state["patience"]
    end
    
    # Callback
    #early_stopping_cb = Flux.throttle(() -> early_stop_cb, 1) #  Check every 3 seconds

    stopped_at = false
    # Training loop
    for i in 1:param.epochs
        Flux.Optimise.train!(loss, par, training_data_loader, opt)
        if early_stop_cb()
            stopped_at = true
            println("Stop at epoch: $i")
            break
        end
    end

    probs = softmax(model(eval_urls))   # Transform output into probabilities
    o = Flux.onecold(probs)             # Transform back the probabilities into labels

    # Return predicted labels and trained model
    return o, model, stopped_at
end

# Create Grid to grid_search from ranges
function par_grid(X::Vector{<:AbstractRange})::Vector{Vector{Float64}}
    # Create the Cartesian product to form the grid
    grid = Iterators.product(X...)

    # Map each tuple in the grid to a vector and collect these vectors into a single vector
    vector_of_vectors = [collect(t) for t in grid]

    return vec(vector_of_vectors) # transform to a vector
end

function grid_search(training_urls::Vector{<:ProductNode}, eval_urls::Vector{<:ProductNode}, training_lables::Vector{Int64}, eval_labels::Vector{Int64}, training_param::Vector{Training_params{Int64, Float64}}, additional_param::Additional_params)::Nothing
    ln = length(training_param)     # Number of combinations of parameters
    # Construct a DataFrame, preallocating space for all parameters combinations
    df = DataFrame(Epochs = Vector{Int64}(undef, ln), 
                   Stopped = Vector{Bool}(undef, ln), 
                   Batchsize = Vector{Int64}(undef, ln),
                   Path_neur_1 = Vector{Int64}(undef, ln),
                   Path_neur_2 = Vector{Int64}(undef, ln),
                   Query_neur_1 = Vector{Int64}(undef, ln),
                   Query_neur_2 = Vector{Int64}(undef, ln),
                   Path_Query_neur = Vector{Int64}(undef, ln),
                   Learning_rate = Vector{Float64}(undef, ln),
                   Precision = Vector{Float64}(undef, ln),
                   Recall = Vector{Float64}(undef, ln),
                   F_score = Vector{Float64}(undef, ln)
    )

    # Cycle for searching the grid
    @inbounds for i in 1:length(training_param)
        predicted_labels, model, stopped = train(training_urls, eval_urls, training_lables, eval_labels, training_param[i], additional_param.prime)   # train the network
        evaluation_metric = evaluate_performance(eval_labels, predicted_labels)    # Evaluate  performance with current network
        filename = "$(training_param[i].epochs)_$(training_param[i].batchsize)_$(training_param[i].learning_rate)_$(training_param[i].path_neur_1)_$(training_param[i].path_neur_2)_$(training_param[i].query_neur_1)_$(training_param[i].query_neur_2)_$(training_param[i].path_query_neur)"   # Construct filename
        save("Julia/Results/$filename.jld2", "Evaluation_metrics", evaluation_metric, "Training_params", training_param[i],"Additional_params", additional_param, "Model", model)   # Save the current network and its parameters

        # Save results in a DataFrame
        df.Epochs[i] = training_param[i].epochs
        df.Batchsize[i] = training_param[i].batchsize
        df.Stopped[i] = stopped
        df.Path_neur_1[i] = training_param[i].path_neur_1
        df.Path_neur_2[i] = training_param[i].path_neur_2
        df.Query_neur_1[i] = training_param[i].query_neur_1
        df.Query_neur_2[i] = training_param[i].query_neur_2
        df.Path_Query_neur[i] = training_param[i].path_query_neur
        df.Learning_rate[i] = training_param[i].learning_rate 
        df.Precision[i] = evaluation_metric.precision
        df.Recall[i] = evaluation_metric.recall
        df.F_score[i] = evaluation_metric.F_score
    end
    CSV.write("Julia/Results/all_results.csv", df)  # Save the DataFrame to a CSV file
    return nothing
end


# epochs, batchise, path_neur_1, path_neur_2, query_neur_1, query_neur_2, path_query_neur, learning_rate
ranges = [20:10:20,  32:33:64, 32:1:32, 16:1:16, 256:1:256, 128:1:128, 64:1:64, 0.001:0.001:0.001]
main(ranges)

